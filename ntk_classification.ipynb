{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dataset = pd.read_csv('Chrome_colors.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ext1Desc</th>\n",
       "      <th>GenericExt1Color</th>\n",
       "      <th>DivisionName</th>\n",
       "      <th>subDivisionName</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ablaze</td>\n",
       "      <td>Red</td>\n",
       "      <td>Scion</td>\n",
       "      <td>Scion Cars</td>\n",
       "      <td>FR-S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ablaze Red Metallic</td>\n",
       "      <td>Red</td>\n",
       "      <td>Suzuki</td>\n",
       "      <td>Suzuki</td>\n",
       "      <td>SX4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adriatic Blue Metallic</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Isuzu</td>\n",
       "      <td>Isuzu Pickups</td>\n",
       "      <td>i-280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agate Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>G-Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akoya Silver Metallic</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Audi</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A8 L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Ext1Desc GenericExt1Color   DivisionName subDivisionName  \\\n",
       "0                  Ablaze              Red          Scion      Scion Cars   \n",
       "1     Ablaze Red Metallic              Red         Suzuki          Suzuki   \n",
       "2  Adriatic Blue Metallic             Blue          Isuzu   Isuzu Pickups   \n",
       "3             Agate Green            Green  Mercedes-Benz   Mercedes-Benz   \n",
       "4   Akoya Silver Metallic           Silver           Audi            Audi   \n",
       "\n",
       "  modelname  \n",
       "0      FR-S  \n",
       "1       SX4  \n",
       "2     i-280  \n",
       "3   G-Class  \n",
       "4      A8 L  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_labeled_names = ([(row['Ext1Desc'],row['GenericExt1Color']) for index, row in color_dataset.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(color_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42461"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(color_labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = color_labeled_names[1000:], color_labeled_names[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = train_set[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aurora Red Metallic', 'Red'),\n",
       " ('Austin Tan Pearl', 'Tan'),\n",
       " ('Austin Tan Pearl', 'Tan'),\n",
       " ('Autumn Bronze Pearl', 'Brown'),\n",
       " ('Azores Green Metallic', 'Green'),\n",
       " ('Azure Blue', 'Blue'),\n",
       " ('Azure Blue (Met)', 'Blue'),\n",
       " ('Azure Blue (Met)', 'Blue'),\n",
       " ('Azure Blue (Met)', 'Blue'),\n",
       " ('Azure Blue Metallic', 'Blue'),\n",
       " ('Azure Blue Pearl', 'Blue'),\n",
       " ('Azurite Blue Pearl', 'Blue'),\n",
       " ('Azzurro California', 'Blue'),\n",
       " ('Azzurro Monaco', 'Blue'),\n",
       " ('Baltic Blue', 'Blue'),\n",
       " ('Blue Ice', 'Blue'),\n",
       " ('Blue Indigo', 'Blue'),\n",
       " ('Blue Jeans', 'Blue'),\n",
       " ('Blue Jeans Metallic', 'Blue')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # or use some other tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = set(word.lower() for passage in train_set for word in word_tokenize(passage[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/20827741/nltk-naivebayesclassifier-training-for-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "test_sentence = \"Blue Velvet Pearl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sent_features = {word.lower(): (word in word_tokenize(test_sentence.lower())) for word in all_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Teal'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_sent_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import random\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aaron', 'male'),\n",
       " ('Abbey', 'male'),\n",
       " ('Abbie', 'male'),\n",
       " ('Abbot', 'male'),\n",
       " ('Abbott', 'male'),\n",
       " ('Abby', 'male'),\n",
       " ('Abdel', 'male'),\n",
       " ('Abdul', 'male'),\n",
       " ('Abdulkarim', 'male')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'f'}, 'male'),\n",
       " ({'last_letter': 'f'}, 'male'),\n",
       " ({'last_letter': 'd'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'l'}, 'male'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'male'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'd'}, 'male'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'r'}, 'male'),\n",
       " ({'last_letter': 'n'}, 'female'),\n",
       " ({'last_letter': 's'}, 'male')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Elizabeth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
